{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"NIST (part 1): Preparing a spectral library for ML\"\n",
    "\n",
    "date: last-modified\n",
    "\n",
    "author:\n",
    "\n",
    "- name: Ralf Gabriels\n",
    "\n",
    "  orcid: 0000-0002-1679-1711\n",
    "\n",
    "  affiliations:\n",
    "    - VIB-UGent Center for Medical Biotechnology, VIB, Belgium\n",
    "    - Department of Biomolecular Medicine, Ghent University, Belgium\n",
    "\n",
    "---\n",
    "\n",
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ProteomicsML/ProteomicsML/blob/main/tutorials/fragmentation/_nist-1-parsing-spectral-library.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "\n",
    "### 1.1 Fragmentation peak intensities\n",
    "\n",
    "In bottom-up proteomics, a peptide fragmentation spectrum (MS2) is the most central\n",
    "source of information to identify a peptide. In traditional identification workflows,\n",
    "only the presence and location (x-axis) of peaks in the spectrum are used to identify\n",
    "the peptide that generated the spectrum. The intensity of these peaks (y-axis) are,\n",
    "however, seldomly used in a comprehensive manner. At most, traditional approaches\n",
    "naively assume that higher intensity is always better.\n",
    "\n",
    "This lack of usage of fragmentation peak intensity patterns can mainly be attributed to\n",
    "their complexity. While the location of certain peaks (e.g., b- and y-ions) can easily\n",
    "be calculated from the amino acid masses, fragment peak intensity follow complex, yet\n",
    "predictable patterns. This makes fragmentation peak intensity values a perfect candidate\n",
    "for machine learning.\n",
    "\n",
    "ML-predicted fragmentation peak intensities have proven their value in many\n",
    "applications, for instance, manual spectrum validation, peptide identification\n",
    "(re)scoring, and for generating *in silico* predicted spectral libraries for\n",
    "data-independant acquisition (DIA) identification.\n",
    "\n",
    "\n",
    "### 1.2 About this tutorial\n",
    "\n",
    "In this three-part tutorial you will learn the basic steps in developing a machine\n",
    "learning (ML) predictor for peptide fragmentation intensity prediction, using a NIST\n",
    "spectral library. The first part handles the preparation and parsing of\n",
    "training data; the second part handles training a traditional ML model with\n",
    "XGBoost, similar to MSÂ²PIP [@Gabriels2019], and the third part handles training\n",
    "a deep learning BiLSTM predictor.\n",
    "\n",
    "1. [Preparing a spectral library for ML][part1]\n",
    "2. [Traditional ML: Gradient boosting][part2]\n",
    "3. [Deep learning: BiLSTM][part3]\n",
    "\n",
    "\n",
    "[part1]: https://www.proteomicsml.org/tutorials/fragmentation/nist-1-parsing-spectral-library.html\n",
    "[part2]: https://www.proteomicsml.org/tutorials/fragmentation/nist-2-traditional-ml-gradient-boosting.html\n",
    "[part3]: https://www.proteomicsml.org/tutorials/fragmentation/nist-3-deep-learning-lstm.html\n",
    "\n",
    "\n",
    "To avoid an overly complex tutorial, some aspects to intensity prediction are simplified\n",
    "or not handled. For example, the resulting models will only be able to predict singly\n",
    "charged b- and y-ions for unmodified peptides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing required python packages\n",
    "! pip install rich numpy pandas matplotlib seaborn spectrum_utils==0.3.5 sklearn --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Finding spectral libraries\n",
    "\n",
    "Training data for peptide fragmentation spectrum intensity prediction consists of\n",
    "spectra that were already identified. The most convenient source of such information are\n",
    "spectral libraries. These are datasets that were compiled from a collection of mass\n",
    "spectrometry runs and usually consist of a single representative spectrum for each\n",
    "peptide that was identified. \n",
    "\n",
    "Many precompiled spectral libraries are available online. You can also generate your\n",
    "own from a collection of proteomics experiments, using software such as SpectraST\n",
    "[@Lam2008].\n",
    "\n",
    "Spectral libraries can be downloaded, for instance, from NIST, the\n",
    "[US National Institute of Standards and Technology](https://chemdata.nist.gov/dokuwiki/doku.php?id=peptidew:cdownload)\n",
    ". For this part of the practical, we will download the\n",
    "[2020 Human HCD library of \"best\" tryptic spectra](https://chemdata.nist.gov/dokuwiki/doku.php?id=peptidew:lib:humanhcd20160503). For ease-of-use, we will download it in the\n",
    "text-based NIST MSP format.\n",
    "\n",
    "The following code cell automatically downloads and extracts the spectral library file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "url = \"https://chemdata.nist.gov/download/peptide_library/libraries/human/HCD/2020_05_19/human_hcd_tryp_best.msp.tar.gz\"\n",
    "library_file = \"human_hcd_tryp_best.msp\"\n",
    "\n",
    "# Download file\n",
    "testfile = urllib.request.urlretrieve(url, f\"{library_file}.tar.gz\")\n",
    "\n",
    "# Extract\n",
    "with tarfile.open(f\"{library_file}.tar.gz\") as f:\n",
    "    f.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the MSP spectral library file by printing the first 10 lines of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(library_file, \"rt\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(line.strip())\n",
    "        if i > 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the beginning of the first spectrum in the spectral library. Each spectrum\n",
    "entry consists of a header with identification data and metadata, and a peak list with\n",
    "three columns:\n",
    "\n",
    " - m/z values\n",
    " - intensity values\n",
    " - peak annotation info\n",
    "\n",
    "\n",
    " As the sequence of the first peptide is `AAAAAAAAAAAAAAAGAGAGAK`, we can assume that\n",
    " this library is ordered alphabetically. You can read through the file to verify this\n",
    " assumption. When preparing datasets for ML, it is important to be aware of such \n",
    " properties, especially when splitting the data into train, test, and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Parsing the MSP spectral library file\n",
    "\n",
    "[Pyteomics](https://pyteomics.readthedocs.io/) is a Python package for proteomics that\n",
    "contains readers for many proteomics-related file formats [@Levitsky2018].\n",
    "Unfortunately, MSP is not one of the supported formats. So first, we need a custom MSP\n",
    "reader function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print, progress  # Rich is a pretty cool library. Google it ;)\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function iterates over each line in the MSP file. Once it has gathered all\n",
    "information for a single spectrum, it uses `yield` to return a dictionary. This means\n",
    "that we can iterate over the function using a `for` loop, and process spectra\n",
    "one-by-one. \n",
    "\n",
    "_If you do not fully understand the function, no problem! This is not the important\n",
    "part of the tutorial._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_msp(filename):\n",
    "    \"\"\"Iterate over MSP spectral library file and return spectra as dicts.\"\"\"\n",
    "    spectrum = {}\n",
    "    mz = []\n",
    "    intensity = []\n",
    "    annotation = []\n",
    "\n",
    "    with progress.open(filename, \"rt\") as f:\n",
    "        for line in f:\n",
    "            # `Name: ` is the first line of a new entry in the file\n",
    "            if line.startswith(\"Name: \"):\n",
    "                if spectrum:\n",
    "                    # Finalize and yield previous spectrum\n",
    "                    spectrum[\"sequence\"] = spectrum[\"Fullname\"].split(\".\")[1]  # Remove the previous/next amino acids\n",
    "                    spectrum[\"mz\"] = np.array(mz, dtype=\"float32\")\n",
    "                    spectrum[\"intensity\"] = np.array(intensity, dtype=\"float32\")\n",
    "                    spectrum[\"annotation\"] = np.array(annotation, dtype=\"str\")\n",
    "                    yield spectrum\n",
    "\n",
    "                    # Define new spectrum\n",
    "                    spectrum = {}\n",
    "                    mz = []\n",
    "                    intensity = []\n",
    "                    annotation = []\n",
    "                \n",
    "                # Extract everything after `Name: `\n",
    "                spectrum[\"Name\"] = line.strip()[6:]\n",
    "\n",
    "            elif line.startswith(\"Comment: \"):\n",
    "                # Parse all comment items as metadata\n",
    "                metadata = [i.split(\"=\") for i in line[9:].split(\" \")]\n",
    "                for item in metadata:\n",
    "                    if len(item) == 2:\n",
    "                        spectrum[item[0]] = item[1]\n",
    "\n",
    "            elif line.startswith(\"Num peaks: \"):\n",
    "                spectrum[\"Num peaks\"] = int(line.strip()[11:])\n",
    "\n",
    "            elif len(line.split(\"\\t\")) == 3:\n",
    "                # Parse peak list items one-by-one\n",
    "                line = line.strip().split(\"\\t\")\n",
    "                mz.append(line[0])\n",
    "                intensity.append(line[1])\n",
    "                annotation.append(line[2].strip('\"'))\n",
    "\n",
    "    # Final spectrum\n",
    "    spectrum[\"sequence\"] = spectrum[\"Fullname\"].split(\".\")[1]  # Remove the previous/next amino acids\n",
    "    spectrum[\"mz\"] = np.array(mz, dtype=\"float32\")\n",
    "    spectrum[\"intensity\"] = np.array(intensity, dtype=\"float32\")\n",
    "    spectrum[\"annotation\"] = np.array(annotation, dtype=\"str\")\n",
    "    yield spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the first spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break allows us to only stop after the first spectrum is defined\n",
    "for spectrum in read_msp(\"human_hcd_tryp_best.msp\"):\n",
    "    print(spectrum[\"Name\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can format the peak list as a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"mz\": spectrum[\"mz\"],\n",
    "    \"intensity\": spectrum[\"intensity\"],\n",
    "    \"annotation\": spectrum[\"annotation\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left-most column denotes the peak annotation. This tells us which ion generated the\n",
    "peak, according to the search engine or library generation software. Note that many\n",
    "peaks (highlighted with a question mark) are not annotated, even though the spectrum was\n",
    "confidently identified.\n",
    "\n",
    "Using the Python package [spectrum_utils](https://spectrum-utils.readthedocs.io/)\n",
    "[@Bittremieux2019] , we can easily visualize the spectrum:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spectrum_utils.spectrum as sus\n",
    "import spectrum_utils.plot as sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sup.spectrum(\n",
    "    sus.MsmsSpectrum(\n",
    "        identifier=spectrum[\"Name\"],\n",
    "        precursor_mz=float(spectrum[\"Parent\"]),\n",
    "        precursor_charge=int(spectrum[\"Charge\"]),\n",
    "        mz=spectrum[\"mz\"],\n",
    "        intensity=spectrum[\"intensity\"]\n",
    "    )\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Preparing spectra for training\n",
    "\n",
    "To use a peptide fragmentation spectrum such as this one as training _target_ for a\n",
    "machine learning model, it needs some preparation and parsing. Usually this comprises\n",
    "of the following steps:\n",
    "\n",
    "1. Normalize the intensities\n",
    "2. Transform the intensities\n",
    "3. Annotate the peaks\n",
    "4. Parse the relevant peak intensities to an format suitable for machine learning\n",
    "\n",
    "For each of these steps, we will write a function that can be reused later on in\n",
    "the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Normalize the intensities\n",
    "\n",
    "Depending on the file format, peak intensities can range from 0 to 1, from 0 to 100,\n",
    "from 0 from 10 000... Machine learning algorithms require the target (and feature)\n",
    "values to be normalized in a specific range. For fragmentation spectra, there are two\n",
    "common options: total ion current (TIC) normalization and base peak normalization.\n",
    "For the former, all intensity values are divided by the total sum of all intensity\n",
    "values in the spectrum. The sum of all normalized intensities will be `1`. For the\n",
    "latter, all intensity values are divided by the most intense peak in the spectrum,\n",
    "resulting in that peak to have normalized intensity  `1`. Here we will implement\n",
    "TIC-normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tic_normalize(msp_spectrum):\n",
    "    tic = np.sum(msp_spectrum[\"intensity\"])\n",
    "    msp_spectrum[\"intensity\"] = msp_spectrum[\"intensity\"] / tic\n",
    "    return msp_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before normalization\n",
    "spectrum[\"intensity\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = tic_normalize(spectrum)\n",
    "\n",
    "# After normalization\n",
    "spectrum[\"intensity\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Transform the intensities\n",
    "\n",
    "The distribution of peak intensities shows us that most peptide fragmentation peaks have\n",
    "a relatively low intensity, while only a few peaks are more intense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Before transform\n",
    "sns.displot(spectrum[\"intensity\"], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the intensities follow a more linear distribution â which is better for machine\n",
    "learning algorithms â we can transform the intensity values. Two methods are often used:\n",
    "square root-tranform, and log-transform. While both methods mostly have the same effect,\n",
    "we will here opt for square root transform, as log-transform results in negative values,\n",
    "which can be cumbersome to deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqrt_transform(msp_spectrum):\n",
    "    msp_spectrum[\"intensity\"] = np.sqrt(msp_spectrum[\"intensity\"])\n",
    "    return msp_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = sqrt_transform(spectrum)\n",
    "\n",
    "# After transform\n",
    "sns.displot(spectrum[\"intensity\"], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Annotate the peaks\n",
    "\n",
    "With the NIST spectral libraries, this step is pretty easy, as peak annotations are already present. If this would not be the case, we can make use of \n",
    "spectrum_utils, which can annotate peaks given the peptide _sequence_ and any _modifications_. See the [spectrum_utils documentation](https://spectrum-utils.readthedocs.io/en/latest/processing.html#peak-annotations) for more info.\n",
    "\n",
    "Here, we use spectrum_utils to annotate the peaks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sup.spectrum(\n",
    "    sus.MsmsSpectrum(\n",
    "        identifier=spectrum[\"Name\"],\n",
    "        precursor_mz=float(spectrum[\"Parent\"]),\n",
    "        precursor_charge=int(spectrum[\"Charge\"]),\n",
    "        mz=spectrum[\"mz\"],\n",
    "        intensity=spectrum[\"intensity\"],\n",
    "        peptide=spectrum[\"sequence\"],\n",
    "    ).annotate_peptide_fragments(25, \"ppm\")\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Parse the relevant peak intensities to an format suitable for machine learning\n",
    "\n",
    "Note in the visualization above that spectrum_utils only annotated b- and y-ions, while in the MSP file many other ion types are also annotated. For simplicity's sake, in this tutorial we will train a model to only predict singly charged b- and y-ions. \n",
    "\n",
    "Let's filter the spectrum for only those peaks. This can be done with regular\n",
    "expressions (regex) and numpy. The regex `^(b|y)([0-9]+)\\/` only matches peak\n",
    "annotations for singly charged b- and y-ions. \n",
    "\n",
    "\n",
    ":::{.callout-tip}\n",
    "[regex101.com](https://regex101.com) is a great website for building and testing\n",
    "regular expressions. You can try out the above mentioned regex at You can investigate it\n",
    "at [regex101.com/r/bgZ7EG/1](https://regex101.com/r/bgZ7EG/1).\n",
    ":::\n",
    "\n",
    "In the `filter_peaks` function below, `numpy.vectorize` is used. What do you think it does and why\n",
    "do we use it here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def filter_peaks(msp_spectrum):\n",
    "    \"\"\"Filter spectrum peaks to only charge 1 b- and y ions.\"\"\"\n",
    "    # Generate the boolean mask\n",
    "    get_mask = np.vectorize(lambda x: bool(re.match(\"^(b|y)([0-9]+)\\/\", x)))\n",
    "    mask = get_mask(msp_spectrum[\"annotation\"])\n",
    "    \n",
    "    # Apply the mask to each peak array\n",
    "    msp_spectrum[\"annotation\"] = msp_spectrum[\"annotation\"][mask]\n",
    "    msp_spectrum[\"mz\"] = msp_spectrum[\"mz\"][mask]\n",
    "    msp_spectrum[\"intensity\"] = msp_spectrum[\"intensity\"][mask]\n",
    "\n",
    "    return msp_spectrum\n",
    "\n",
    "spectrum = filter_peaks(spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sup.spectrum(\n",
    "    sus.MsmsSpectrum(\n",
    "        identifier=spectrum[\"Name\"],\n",
    "        precursor_mz=float(spectrum[\"Parent\"]),\n",
    "        precursor_charge=int(spectrum[\"Charge\"]),\n",
    "        mz=spectrum[\"mz\"],\n",
    "        intensity=spectrum[\"intensity\"],\n",
    "        peptide=spectrum[\"sequence\"]\n",
    "    ).annotate_peptide_fragments(25, \"ppm\")\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the spectrum indeed only contains singly charged b- and y-ions. Note the nice gausian-like distributions of equally-distanced b- and y-ions. This is a feature specific for this peptide spectrum. Can you guess why? Tip: Take a look at the peptide sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, all peaks are listed together in single numpy arrays, sorted by m/z values. For training a machine learning model, we need the intensity values in a more suitable structure. As we are planning to only predict simple singly charged b- and y-ions, we can create two arrays â one for each ion type â with the ions sorted by ion number:\n",
    "\n",
    "```python\n",
    "parsed_intensity = {\n",
    "    \"b\": [b1, b2, b3, b4 ... bN],\n",
    "    \"y\": [y1, y2, y3, y4 ... yN]\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "where N is the total number of possible fragments for that peptide sequence. Quick question: What value will N have for our peptide with sequence `AAAAAAAAAAAAAAAGAGAGAK`?\n",
    "\n",
    "The following function builds upon the `filter_peaks` function to not only filter the correct ion types, but also order them properly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_peaks(msp_spectrum, ion_type):\n",
    "    # Generate vectorized functions\n",
    "    get_ions = np.vectorize(lambda x: bool(re.match(f\"^({ion_type})([0-9]+)\\/\", x)))\n",
    "    get_ion_order = np.vectorize(lambda x: re.match(f\"^({ion_type})([0-9]+)\\/\", x)[2])\n",
    "\n",
    "    # Get mask with requested ion types\n",
    "    mask = get_ions(msp_spectrum[\"annotation\"])\n",
    "\n",
    "    # Create empty array with for all possible ions\n",
    "    n_ions = len(msp_spectrum[\"sequence\"]) - 1\n",
    "    parsed_intensity = np.zeros(n_ions)\n",
    "\n",
    "    # Check if any ions of this type are present\n",
    "    if mask.any():\n",
    "        # Filter for ion type and sort\n",
    "        ion_order = get_ion_order(msp_spectrum[\"annotation\"][mask]).astype(int) - 1\n",
    "        # Add ions to correct positions in new array\n",
    "        parsed_intensity[ion_order] = msp_spectrum[\"intensity\"][mask]\n",
    "\n",
    "    try:\n",
    "        msp_spectrum[\"parsed_intensity\"][ion_type] = parsed_intensity\n",
    "    except KeyError:\n",
    "        msp_spectrum[\"parsed_intensity\"] = {}\n",
    "        msp_spectrum[\"parsed_intensity\"][ion_type] = parsed_intensity\n",
    "    \n",
    "    return msp_spectrum\n",
    "\n",
    "spectrum = parse_peaks(spectrum, \"b\")\n",
    "spectrum = parse_peaks(spectrum, \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum['parsed_intensity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! These values are now ready to be used as prediction targets for a machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Parse the full spectral library\n",
    "\n",
    "Now that all functions for spectrum preparation are written, we can parse the full spectral library. Let's first explore some of the basic statistics of this\n",
    "library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Exploring basic spectral library statistics\n",
    "\n",
    "#### Reading the full spectrum file\n",
    "\n",
    "Let's read the full spectrum file to extract some statistics. To limit the amount of\n",
    "data we keep in memory (this full MSP file is almost 2GB!), we can process the intensity\n",
    "values of each spectrum while parsing and only keep the parsed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_list = []\n",
    "for msp_spectrum in read_msp(\"human_hcd_tryp_best.msp\"):\n",
    "    # Process intensities\n",
    "    msp_spectrum = tic_normalize(msp_spectrum)\n",
    "    msp_spectrum = sqrt_transform(msp_spectrum)\n",
    "    msp_spectrum = parse_peaks(msp_spectrum, \"b\")  # Adds `parsed_intensity` > `b`\n",
    "    msp_spectrum = parse_peaks(msp_spectrum, \"y\")  # Adds `parsed_intensity` > `y`\n",
    "\n",
    "    # Parse metadata\n",
    "    spectrum = {\n",
    "        \"sequence\": msp_spectrum[\"sequence\"],\n",
    "        \"modifications\": msp_spectrum[\"Mods\"],\n",
    "        \"charge\": int(msp_spectrum[\"Charge\"]),\n",
    "        \"nce\": float(msp_spectrum[\"NCE\"]),\n",
    "        \"parsed_intensity\": msp_spectrum[\"parsed_intensity\"]\n",
    "    }\n",
    "\n",
    "    # Append to list\n",
    "    spectrum_list.append(spectrum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a Pandas DataFrame from the list of spectrum dictionaries, allows us to easily explore the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_df = pd.DataFrame(spectrum_list)\n",
    "spectrum_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a Pandas DataFrame out of `spectrum_list` is so simple because it is a \n",
    "list of consistent dictionaries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total number of specta\n",
    "\n",
    "Low-hanging fruit first: How many spectra are in the full library?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spectrum_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precursor charge state\n",
    "\n",
    "A different precursor charge state can heavily alter peptide fragmentation. It is therefore important to have a representative amount of peptide spectra for each charge state in the spectral library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=spectrum_df, x=\"charge\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peptide length\n",
    "\n",
    "Idem for the length of the peptide sequence. It usually makes sense to filter \n",
    "the train dataset for peptides within a certain length range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(spectrum_df[\"sequence\"].str.len())\n",
    "plt.xlabel(\"Sequence length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_df[\"sequence\"].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(spectrum_df[\"sequence\"].str.len() > 35).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset, the minimum peptide length is 6, while the maximum is 50.\n",
    "Nevertheless, only 1.2% have a peptide lenght higher than 35."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Peptide modifications\n",
    "\n",
    "Likewise, peptide modifications can influence peptide fragmentation. How many of the spectra in our library come from modified peptides?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modification_state = (spectrum_df[\"modifications\"] == \"0\").map({True: \"Unmodified\", False: \"Modified\"})\n",
    "sns.countplot(x=modification_state)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collision energy\n",
    "\n",
    "Similarly, the fragmentation collision energy (CE) might influence the observed\n",
    "fragmentation patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(spectrum_df[\"nce\"], bins=30)\n",
    "plt.xlabel(\"NCE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the range of the x-axis, which was automatically chosen by the plotting library. It seems to start at 0, which indicates that some values are very low..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(spectrum_df[\"nce\"] == 0.0).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, it seems that some peptide spectra have CE `0`, which most likely means that the\n",
    "true CE setting is not known. We can either opt to not use CE as a feature for training,\n",
    "or to remove these spectra from the dataset. Including these values would introduce\n",
    "unwanted noise in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicate entries?\n",
    "\n",
    "An important aspect to compiling training data for machine learning is whether or not entries are duplicated. With spectral libraries, matters are complicated by multiple levels of \"uniqueness\":\n",
    "\n",
    "- Peptide level: Unique sequence\n",
    "- Peptidoform level: Unique sequence & modifications\n",
    "- Precursor level: Unique sequence & modifications & charge\n",
    "\n",
    "More parameters can be included for \"uniqueness\", such as instrument and acquisition properties: CE, fragmentation method (beam-type CID (\"HCD\"), trap-type CID, ETD, EAD...), acquisition method (Orbitrap, ion trap, TOF...). In this tutorial, we are using only HCD Orbitrap data, which makes things a bit simpler. Nevertheless, this will impact the application domain of the final models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.DataFrame({\n",
    "    \"Level\": [\n",
    "        \"Full library\",\n",
    "        \"Precursor\",\n",
    "        \"Peptidoform\",\n",
    "        \"Peptide\",\n",
    "    ],\n",
    "    \"Count\": [\n",
    "        spectrum_df.shape[0],\n",
    "        spectrum_df[[\"sequence\", \"modifications\", \"charge\"]].drop_duplicates().shape[0],\n",
    "        spectrum_df[[\"sequence\", \"modifications\"]].drop_duplicates().shape[0],\n",
    "        spectrum_df[\"sequence\"].unique().shape[0],\n",
    "    ],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=counts, x=\"Level\", y=\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like this library was already filtered for uniqueness on the precursor level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Selecting data\n",
    "\n",
    "For selecting training data, we will apply some additional filters:\n",
    "\n",
    "- While plain amino acid sequences are straightforward to encode, peptide modifications complicate matters. For simplicity's sake, we will therefore not open the \"can of modifications\" in this tutorial.\n",
    "- As we might want to use CE as a feature, we can remove the small amount of entries that are missing the a CE value\n",
    "- To make the training task a bit less complex, we can limit peptide length to 35. Although the maximum peptide length in this library is 50, only 4944 spectra have a peptide length of over 35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_df = spectrum_df[\n",
    "    (modification_state == \"Unmodified\") &\n",
    "    (spectrum_df[\"sequence\"].str.len() <= 35) &\n",
    "    (spectrum_df[\"nce\"] != 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many spectra we retained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Train / validation / test split\n",
    "\n",
    "Now that we have our data, we can filter it to a final set for training and validation\n",
    "and a final set for testing. A small reminder of what these terms mean:\n",
    "\n",
    "- Training data: For training the model\n",
    "- Validation data: For validating the model while optimizing hyperparameters\n",
    "- Testing data: For final testing of model that was trained with the best\n",
    "hyperparameters (according to the validation data), right before deployment\n",
    "\n",
    "The testing data cannot be used until a final model is trained, and serves as a last\n",
    "test before deployment. It should not be used before a final model is selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "train_val_peptides, test_peptides = train_test_split(spectrum_df[\"sequence\"].unique(), train_size=0.9)\n",
    "train_val_spectra = spectrum_df[spectrum_df[\"sequence\"].isin(train_val_peptides)]\n",
    "test_spectra = spectrum_df[spectrum_df[\"sequence\"].isin(test_peptides)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we not apply `train_test_split()` directly on `spectrum_df`, but instead on `spectrum_df[\"sequence\"].unique()`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Saving the parsed library for the next tutorial parts\n",
    "\n",
    "We will be saving the parsed spectral library to Arrow Feather files, a fast and\n",
    "efficient binary format that can easily be read and written from Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_spectra.reset_index().to_feather(\"fragmentation-nist-humanhcd20160503-parsed-trainval.feather\")\n",
    "test_spectra.reset_index().to_feather(\"fragmentation-nist-humanhcd20160503-parsed-test.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue with part 2 of this tutorial:<br>\n",
    "ð[Traditional ML: Gradient boosting][part2]\n",
    "\n",
    "[part2]: https://www.proteomicsml.org/tutorials/fragmentation/nist-2-traditional-ml-gradient-boosting.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1b82a09351d6492f9a7b4e40209cd514": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_51179dc6ad9c4e6e945e40ed49e5e971",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Working... <span style=\"color: #f92672; text-decoration-color: #f92672\">ââââââââââ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">âºâââââââââââââââââââââââââââââ</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 26%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:05:20</span>\n</pre>\n",
         "text/plain": "Working... \u001b[38;2;249;38;114mââââââââââ\u001b[0m\u001b[38;5;237mâº\u001b[0m\u001b[38;5;237mâââââââââââââââââââââââââââââ\u001b[0m \u001b[35m 26%\u001b[0m \u001b[36m0:05:20\u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "51179dc6ad9c4e6e945e40ed49e5e971": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
