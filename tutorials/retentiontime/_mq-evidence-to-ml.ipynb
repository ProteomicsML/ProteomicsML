{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9514ecf5",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Preparing a retention time data set for machine learning\"\n",
    "date: last-modified\n",
    "author:\n",
    "- name: Robbin Bouwmeester\n",
    "  orcid: 0000-0001-6807-7029\n",
    "  affiliations:\n",
    "    - VIB-UGent Center for Medical Biotechnology, VIB, Belgium\n",
    "    - Department of Biomolecular Medicine, Ghent University, Belgium\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7be11",
   "metadata": {},
   "source": [
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ProteomicsML/ProteomicsML/blob/main/tutorials/fragmentation/_nist-1-parsing-spectral-library.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba1e77",
   "metadata": {},
   "source": [
    "# Preparing a retention time data set for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4152277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "from pygam import LinearGAM, s, f\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c18a058",
   "metadata": {},
   "source": [
    "In this tutorial you will learn how to go from MaxQuant evidence files to a data set that is ready for training a retention time prediction model. Retention time is the time it takes for an analyte travels through a column. The travel time depends on the interaction with the stationary phase (usually C18 for proteomics) and mobile phase. Where the mobile phase consists of solvents and changes in physicochemical properties over time with a predefined gradient. The stationary phase remains the same over time. This allows for peptides to elude at different time points, e.g., when it prefers to interact with the mobile phase at a certain percentage of the hydrophobic solvent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa59d00",
   "metadata": {},
   "source": [
    "The retention time between different runs can differ significantly and depending on the abundance of the precusor calling the elution apex can be difficult. This means we need to preprocess the data before it is used for machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e5f0f2",
   "metadata": {},
   "source": [
    "## Reading and formatting input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bd7c4c",
   "metadata": {},
   "source": [
    "We will not need all the columns, define those that might be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_columns = [\n",
    "    'Raw file', 'Sequence', 'Length', 'Modifications', 'Modified sequence',\n",
    "    'Retention time','Retention length','Calibrated retention time',\n",
    "    'Calibrated retention time start', 'Calibrated retention time finish',\n",
    "    'Retention time calibration', 'Match time difference',\"Intensity\", \"PEP\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e79c792",
   "metadata": {},
   "source": [
    "Read the input files, here a csv. If you read the standard txt you need to modify the read_csv with:\n",
    "\n",
    "```pd.read_csv(\"evid_files/PXD028248_evidence_selected_columns.csv\",sep=\"\\t\",low_memory=False)```\n",
    "\n",
    "Fill all the NA values with 0.0 and filter on only the most confident identificaitons (PEP <= 0.001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dfc690",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('https://github.com/ProteomicsML/ProteomicsML/blob/main/datasets/retentiontime/PXD028248/PXD028248_evidence_selected_columns.zip', 'r') as zipObj:\n",
    "   zipObj.extractall()\n",
    "    \n",
    "evid_df = pd.read_csv(\"PXD028248_evidence_selected_columns.csv\",low_memory=False)\n",
    "evid_df.fillna(0.0,inplace=True)\n",
    "evid_df = df[df[\"PEP\"] <= 0.001][sel_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d0db25",
   "metadata": {},
   "source": [
    "The file in a pandas dataframe looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7957e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1699e802",
   "metadata": {},
   "source": [
    "As you can see in this example there are many of the same peptidoforms (minus charge) for the different runs. We will want to create a single value for each peptidoform per run in a matrix instead of a single peptidoform+run combo per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f7e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retention_dict = {}\n",
    "\n",
    "# Group by the raw file\n",
    "for gidx,g in evid_df.groupby(\"Raw file\"):\n",
    "    # Group by peptidoform and take the mean for each group\n",
    "    retention_dict[gidx]  = g.groupby(\"Modified sequence\").mean()[\"Calibrated retention time\"].to_dict()\n",
    "    \n",
    "#Transform the dictionary in a df where each row is a peptidoform and each column a run\n",
    "retention_df = pd.DataFrame(retention_dict)\n",
    "\n",
    "retention_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e009b6",
   "metadata": {},
   "source": [
    "We can than have a look at the absence of each peptidoform in all runs (value = absence in that many runs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb3bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prevelence_peptides = retention_df.isna().sum(axis=1)\n",
    "print(prevelence_peptides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b4475d",
   "metadata": {},
   "source": [
    "We can penalize the absence the absence of highly abundant peptidoforms per run (lower = more abundant peptidoforms present) by taking the dot product of presence/absence in the matrix and the above absence scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_per_run = retention_df.isna().astype(int).T.dot(prevelence_peptides)\n",
    "score_per_run.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da03b986",
   "metadata": {},
   "source": [
    "We will use a single run to align all the first experiments against, this is the one with the lowest penalty score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_highest_overlap_score = score_per_run.sort_values(ascending=True).index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1581a65",
   "metadata": {},
   "source": [
    "## Retention time alignment between runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f175e68",
   "metadata": {},
   "source": [
    "The first step after reading and loading the data is to align retention times between runs. Here we will use splines in a GAM for that. The algorithm below follows these steps:\n",
    "\n",
    "1. Iterate over all runs, sorted by the earlier defined penalty score\n",
    "2. Obtain the overlapping peptidoforms between runs\n",
    "3. If there are less than 20 peptidoforms skip that run\n",
    "4. Divide the overlapping peptides into equidistant bins and enforce a percentage of the bins to be filled with a least one peptidoform (now 200 bins and 75 % occupancy). If requirements are not met skip that run.\n",
    "5. Fit the GAM with splines between the reference set and the selected run\n",
    "6. Calculate the error between aligned and values in the reference set. If selected it will run a second stage of the GAM filtering out any data points that were selected to have an error that is too high\n",
    "7. Assign aligned values to a new matrix\n",
    "8. Change the reference dataset to be the median of all aligned runs and the initial reference run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb5fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constraints = \"monotonic_inc\"\n",
    "constraints = \"none\"\n",
    "\n",
    "# Align parameters\n",
    "perform_second_stage_robust = True\n",
    "error_filter_perc = 0.005\n",
    "num_splines = 150\n",
    "min_coverage = 0.75\n",
    "coverage_div = 200\n",
    "plot_res_every_n = 20\n",
    "min_overlap = 20\n",
    "\n",
    "run_highest_overlap_score = score_per_run.sort_values(ascending=True).index[0]\n",
    "\n",
    "unique_peptides = []\n",
    "unique_peptides.extend(list(retention_df[retention_df[run_highest_overlap_score].notna()].index))\n",
    "\n",
    "retention_df_aligned = retention_df.copy()\n",
    "\n",
    "keep_cols = [run_highest_overlap_score]\n",
    "\n",
    "error_filter_perc_threshold = max(retention_df[run_highest_overlap_score])*error_filter_perc\n",
    "\n",
    "# Iterate over runs sorted by a penalty score\n",
    "for idx,align_name in enumerate(score_per_run.sort_values(ascending=True)[1:].index):\n",
    "    # Check overlap between peptidoforms\n",
    "    non_na_sel = (retention_df[align_name].notna()) & (retention_df[run_highest_overlap_score].notna())\n",
    "    \n",
    "    # Continue if insufficient overlapping peptides\n",
    "    if len(retention_df[run_highest_overlap_score][non_na_sel].index) < min_overlap:\n",
    "        continue\n",
    "    \n",
    "    # Check spread of overlapping peptidoforms, continue if not sufficient\n",
    "    if (len(set(pd.cut(retention_df[align_name][non_na_sel], coverage_div, include_lowest = True))) / coverage_div) < min_coverage:\n",
    "        continue\n",
    "    \n",
    "    # Fit the GAM\n",
    "    gam_model_cv = LinearGAM(s(0, n_splines=num_splines), constraints=constraints, verbose=True).fit(\n",
    "                                                            retention_df[align_name][non_na_sel], \n",
    "                                                            retention_df[run_highest_overlap_score][non_na_sel])\n",
    "    \n",
    "    \n",
    "    # Plot results alignment\n",
    "    print(f\"---{align_name}---\")\n",
    "    if idx % plot_res_every_n == 0:\n",
    "        plt.scatter(\n",
    "                    retention_df[run_highest_overlap_score][non_na_sel],\n",
    "                    retention_df[align_name][non_na_sel],\n",
    "                    alpha=0.05,\n",
    "                    s=10,\n",
    "                    label=\"Align set\"\n",
    "                )\n",
    "\n",
    "        plt.scatter(\n",
    "                    retention_df[run_highest_overlap_score][non_na_sel],\n",
    "                    gam_model_cv.predict(retention_df[align_name][non_na_sel]),\n",
    "                    alpha=0.05,\n",
    "                    s=10,\n",
    "                    label=\"Align set aligend to reference\"\n",
    "                )\n",
    "        plt.plot(\n",
    "            [\n",
    "            min(retention_df[run_highest_overlap_score][non_na_sel]),\n",
    "            max(retention_df[run_highest_overlap_score][non_na_sel])\n",
    "\n",
    "            ],\n",
    "            [\n",
    "                min(retention_df[run_highest_overlap_score][non_na_sel]),\n",
    "                max(retention_df[run_highest_overlap_score][non_na_sel])\n",
    "\n",
    "            ],\n",
    "            c=\"black\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=1.0\n",
    "        )\n",
    "        \n",
    "        plt.xlabel(\"Retention time reference set\")\n",
    "        plt.ylabel(\"Reference - aligned align set\")\n",
    "        leg = plt.legend()\n",
    "        for lh in leg.legendHandles: \n",
    "            lh.set_alpha(1)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        plt.scatter(\n",
    "                    retention_df[run_highest_overlap_score][non_na_sel],\n",
    "                    retention_df[align_name][non_na_sel]-retention_df[run_highest_overlap_score][non_na_sel],\n",
    "                    alpha=0.05,\n",
    "                    s=10\n",
    "                )\n",
    "\n",
    "        plt.scatter(\n",
    "                    retention_df[run_highest_overlap_score][non_na_sel],\n",
    "                    gam_model_cv.predict(retention_df[align_name][non_na_sel])-retention_df[run_highest_overlap_score][non_na_sel],\n",
    "                    alpha=0.05,\n",
    "                    s=10\n",
    "                )\n",
    "        \n",
    "        plt.title(\"Residual plot\")\n",
    "        \n",
    "        plt.axhline(\n",
    "            y = 0.0, \n",
    "            color = \"black\",\n",
    "            linewidth=1.0,\n",
    "            linestyle = \"--\"\n",
    "        )\n",
    "        \n",
    "        plt.xlabel(\"Retention time reference\")\n",
    "        plt.xlabel(\"Retention time reference\")\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    # Calculate errors and create filter that can be used in the second stage\n",
    "    errors = abs(gam_model_cv.predict(retention_df[align_name][non_na_sel])-retention_df[run_highest_overlap_score][non_na_sel])\n",
    "    error_filter = errors < error_filter_perc_threshold\n",
    "    \n",
    "    # Perform a second stage GAM removing high error from previous fit\n",
    "    if perform_second_stage_robust:\n",
    "        gam_model_cv = LinearGAM(s(0, n_splines=num_splines), constraints=constraints, verbose=True).fit(\n",
    "                                                                retention_df[align_name][non_na_sel][error_filter], \n",
    "                                                                retention_df[run_highest_overlap_score][non_na_sel][error_filter])\n",
    "\n",
    "        if idx % plot_res_every_n == 0:\n",
    "            plt.scatter(\n",
    "                        retention_df[run_highest_overlap_score][non_na_sel][error_filter],\n",
    "                        retention_df[align_name][non_na_sel][error_filter]-retention_df[run_highest_overlap_score][non_na_sel][error_filter],\n",
    "                        alpha=0.05,\n",
    "                        s=10\n",
    "                    )\n",
    "\n",
    "            plt.scatter(\n",
    "                        retention_df[run_highest_overlap_score][non_na_sel][error_filter],\n",
    "                        gam_model_cv.predict(retention_df[align_name][non_na_sel][error_filter])-retention_df[run_highest_overlap_score][non_na_sel][error_filter],\n",
    "                        alpha=0.05,\n",
    "                        s=10\n",
    "                    )\n",
    "            plt.title(\"Residual plot second stage GAM\")\n",
    "            plt.axhline(\n",
    "                y = 0.0, \n",
    "                color = \"black\",\n",
    "                linewidth=1.0,\n",
    "                linestyle = \"--\"\n",
    "            )\n",
    "            \n",
    "            plt.xlabel(\"Retention time reference set\")\n",
    "            plt.ylabel(\"Reference - aligned align set\")\n",
    "\n",
    "            plt.show()\n",
    "    \n",
    "    # Write alignment to new matrix\n",
    "    retention_df_aligned.loc[retention_df[align_name].notna(),align_name] = gam_model_cv.predict(retention_df.loc[retention_df[align_name].notna(),align_name])\n",
    "\n",
    "    unique_peptides.extend(list(retention_df[retention_df[align_name].notna()].index))\n",
    "    \n",
    "    keep_cols.append(align_name)\n",
    "        \n",
    "    # Create reference set based on aligned retention times\n",
    "    retention_df[\"median_aligned\"] = retention_df_aligned[keep_cols].median(axis=1)\n",
    "    run_highest_overlap_score = \"median_aligned\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb645cc",
   "metadata": {},
   "source": [
    "The data points acquired looks as the following vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed67603",
   "metadata": {},
   "outputs": [],
   "source": [
    "retention_df_aligned[keep_cols].median(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b8d29",
   "metadata": {},
   "source": [
    "If we look at the standard deviation we can see that this is still relatively large for some peptidoforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca99feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(retention_df_aligned[keep_cols].std(axis=1),bins=500)\n",
    "plt.xlabel(\"Standard deviation retention time\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(retention_df_aligned[keep_cols].std(axis=1),bins=500)\n",
    "plt.xlim(0,7.5)\n",
    "plt.xlabel(\"Standard deviation retention time (zoomed)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da9795",
   "metadata": {},
   "source": [
    "In addition to the std there is another factor that can play a big role, the amount of times a peptidoform was observed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf3ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(retention_df_aligned[keep_cols].notna().sum(axis=1),bins=100)\n",
    "plt.xlabel(\"Count peptidoforms across runs\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(retention_df_aligned[keep_cols].notna().sum(axis=1),bins=100)\n",
    "plt.xlabel(\"Count peptidoforms across runs (zoomed)\")\n",
    "plt.xlim(0,20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fc07f9",
   "metadata": {},
   "source": [
    "If we plot both values against each other we get the following plot (the lines indicate possible thresholds):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd46733",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    retention_df_aligned[keep_cols].notna().sum(axis=1),\n",
    "    retention_df_aligned[keep_cols].std(axis=1),\n",
    "    s=5,\n",
    "    alpha=0.1\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Standard deviation retention time\")\n",
    "plt.xlabel(\"Count peptidoforms across runs\")\n",
    "\n",
    "plt.axhline(\n",
    "    y = 2.0, \n",
    "    color = \"black\",\n",
    "    linewidth=1.0,\n",
    "    linestyle = \"--\"\n",
    ")\n",
    "\n",
    "plt.axvline(\n",
    "    x = 5.0, \n",
    "    color = \"black\",\n",
    "    linewidth=1.0,\n",
    "    linestyle = \"--\"\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a961da5b",
   "metadata": {},
   "source": [
    "If we set a threshold for a minimum of 5 observations and a maximum standard deviation of 2 we get the following final data set. Here we take the median for each peptidoform across all runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d5a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_observations = 5\n",
    "max_std = 2.0\n",
    "\n",
    "observation_filter = retention_df_aligned[keep_cols].notna().sum(axis=1) > min_observations\n",
    "std_filter = retention_df_aligned[keep_cols].std(axis=1) < max_std\n",
    "\n",
    "retention_df_aligned[keep_cols][(observation_filter) & (std_filter)].median(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
